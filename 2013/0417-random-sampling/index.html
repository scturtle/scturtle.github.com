<!doctype html>
<html>
  <head>
    <meta charset=utf-8>
    <meta name="viewport" content="width=device-width, initial-scale=1.0"/>
    <title>Random Sampling | ScTurtle&#39;s Pool</title>
    <link rel="shortcut icon" href="/static/favicon.png"/>
    <link href='https://fonts.googleapis.com/css?family=Open+Sans:400,400italic' rel='stylesheet' type='text/css'>
    <link rel="stylesheet" href="/static/style.css" type="text/css">
    <link rel="stylesheet" href="/static/pygments.css" type="text/css">
    <link href="/atom.xml" rel="alternate" title="ScTurtle&#39;s Pool" type="application/atom+xml">
  </head>
  <body>
    <div class=container>
      <div class=header>
        <a href='/'>ScTurtle&#39;s Pool</a>
      </div>
      <div class=navigation>
        <ul>
          <li><a href='/'>blog</a>
          <li><a href='/archive.html'>archive</a>
          <li><a href='/tags/'>tags</a>
          <li><a href='/about/'>about</a>
        </ul>
      </div>
      <div class=body>


<article>
<h1 class=title>Random Sampling</h1>
<p class=info>
Apr 17, 2013
<a href='/tags/math.html'>#math</a>
</p>
<p>Given a set of items, choosing random one with equal probability can be done by <code>random.choice(items)</code>.
But what if we are given items one by one without knowing the length of the whole set?</p>
<p>There is a simple algorithm: For the <mathjax>$k$</mathjax>-th item, we give up previous selection and choose this one with probability <mathjax>$\frac 1 k$</mathjax>.
Proof as follows: If we select the <mathjax>$k$</mathjax>-th item, it means that we choose it with probability <mathjax>$\frac 1 k$</mathjax> and give up all successors. 
Product of probabilities of all these choices is:</p>
<p><mathjax>$$ p_k = \frac 1 k \times \frac {k} {k+1} \times \cdots \times \frac {n-2}{n-1} \times \frac {n-1} n = \frac 1 n $$</mathjax></p>
<p>Codes in Python:</p>
<div class="codehilite"><pre><span class="kn">import</span> <span class="nn">random</span>

<span class="k">def</span> <span class="nf">choice</span><span class="p">(</span><span class="n">items</span><span class="p">):</span>
    <span class="n">selection</span> <span class="o">=</span> <span class="bp">None</span>
    <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">item</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">items</span><span class="p">):</span>
        <span class="k">if</span> <span class="n">random</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">i</span><span class="p">)</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="n">selection</span> <span class="o">=</span> <span class="n">item</span>
    <span class="k">return</span> <span class="n">selection</span>
</pre></div>


<p>We can generalize this algorithm. For a set of items, each one is associated with a weight <mathjax>$w_i$</mathjax>.
Our goal is to select a random one based on its weight ratio.
The algorithm is similar to the previous one: For the <mathjax>$k$</mathjax>-th item, replace the current selection with it with probability <mathjax>$\frac {w_k} {\sum_{i=1}^k w_i}$</mathjax>.
Proof is analogical:</p>
<p><mathjax>$$p_k = \frac {w_k} {\sum_{i=1}^k w_i} \times \frac {\sum_{i=1}^k w_i} {\sum_{i=1}^{k+1} w_i} 
\times \cdots \times \frac {\sum_{i=1}^{n-2} w_i} {\sum_{i=1}^{n-1} w_i} \times \frac {\sum_{i=1}^{n-1} w_i} {\sum_{i=1}^{n} w_i} = \frac {w_k} {\sum_{i=1}^n w_i}$$</mathjax></p>
<p>Codes in Python:</p>
<div class="codehilite"><pre><span class="k">def</span> <span class="nf">weightedChoice</span><span class="p">(</span><span class="n">items</span><span class="p">,</span> <span class="n">weights</span><span class="p">):</span>
    <span class="n">selection</span> <span class="o">=</span> <span class="bp">None</span>
    <span class="n">total_weight</span> <span class="o">=</span> <span class="mf">0.0</span>
    <span class="k">for</span> <span class="n">item</span><span class="p">,</span> <span class="n">weight</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">items</span><span class="p">,</span> <span class="n">weights</span><span class="p">):</span>
        <span class="n">total_weight</span> <span class="o">+=</span> <span class="n">weight</span>
        <span class="k">if</span> <span class="n">random</span><span class="o">.</span><span class="n">random</span><span class="p">()</span> <span class="o">*</span> <span class="n">total_weight</span> <span class="o">&lt;</span> <span class="n">weight</span><span class="p">:</span>
            <span class="n">selection</span> <span class="o">=</span> <span class="n">item</span>
    <span class="k">return</span> <span class="n">selection</span>
</pre></div>


<p>There is another amazing method to do this weighted random sampling:
For each item, get a random <mathjax>$r_i \in [0, 1]$</mathjax>,
and <em>reweight</em> this item as <mathjax>$w'_i = r_i^{1 / {w_i}}$</mathjax>.
Then we can select the one with the top new weight. Proof of this is a bit annoying.</p>
<p>If we choose the <mathjax>$i$</mathjax>-th item at last, this means <mathjax>$\forall j\neq i, w'_j &lt;w'_i$</mathjax>. As <mathjax>$r_i \in [0, 1]$</mathjax>, the probability is:</p>
<p><mathjax>$$ p_i = \int_0^1 p(\forall j\neq i, w'_j &lt;w'_i)\ \mathrm{d}\ r_i $$</mathjax></p>
<p><mathjax>$r_j$</mathjax> is independent with each other. So:</p>
<p><mathjax>$$ p_i = \int_0^1 \prod_{j \neq i} p(w'_j &lt;w'_i)\ \mathrm{d} \ r_i $$</mathjax></p>
<p>As <mathjax>$r_j \in [0, 1]$</mathjax>, the inner probability can be simplified as:</p>
<p><mathjax>$$ p(w'_j &lt;w'_i) = p(r_j^{1 / w_j} &lt; r_i^{1 / w_i}) = p(r_j &lt; r_i^{w_j / w_i}) = r_i^{w_j / w_i} $$</mathjax></p>
<p>So:</p>
<p><mathjax>$$ p_i = \int_0^1 \prod_{j \neq i} r_i^{w_j / w_i}\ \mathrm{d}\ r_i
= \int_0^1 r_i^{(w-w_i) / w_i}\ \mathrm{d}\ r_i = \frac {w_i} w $$</mathjax></p>
<p>Same as our expectation.</p>
<p>This blog is basically a summary of
<a href="http://www.gocalf.com/blog/random-selection.html">these</a>
<a href="http://www.gocalf.com/blog/weighted-random-selection.html">three</a>
<a href="http://www.gocalf.com/blog/weighted-random-selection-2.html">blogs</a>.
Refer to them for more content.</p>
</article>
<div id="show_disqus"><a onclick="load_disqus();return false;" href="##">Show comments</a></div>
<div id="disqus_thread"></div>


      </div>
      <div class=footer>
        <p><a href='https://github.com/scturtle/turtleblog'>turtleblog</a> &copy; 2014 scturtle
        <p> <a href="mailto:scturtle@gmail.com">mail</a>,
        <a href="https://twitter.com/scturtle">twitter</a>,
        <a href="https://github.com/scturtle">github</a>,
        <a href='/atom.xml' rel=alternate title="Recent Blogs | ScTurtle&#39;s Pool">feed</a>
      </div>
    </div>

<script type="text/javascript">
  function load_disqus() {
    var dsq = document.createElement('script');
    dsq.type = 'text/javascript'; dsq.async = true;
    dsq.src = 'http://scturtlespool.disqus.com/embed.js';
    (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
    document.getElementById('show_disqus').style.display='none';
  };
</script>

<script type="text/javascript" 
  src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"> </script>
<script type="text/x-mathjax-config"> 
MathJax.Hub.Config({
  tex2jax: {
    inlineMath: [['$','$'], ["\\(","\\)"]],
    processEscapes: true
  },
}); </script>

<script type="text/javascript">
  var _gaq = _gaq || [];
  _gaq.push(['_setAccount', 'UA-33410961-1']);
  _gaq.push(['_trackPageview']);
  (function() {
    var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
    ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
    var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
  })();
</script>
  </body>
</html>